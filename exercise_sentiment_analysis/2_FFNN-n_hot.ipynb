{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis - Feedforward NN with n-hot features in DyNet\n",
    "\n",
    "The following code provides a base implementation of a feedforward neural network in `DyNet` with n-hot features. One difference to `sklearn` is that both features and labels need to be mapped to indices. \n",
    "\n",
    "Inspect the code and try to understand the bits and pieces. How are the parameters defined? How is the model created? And how is the model trained?\n",
    "\n",
    "NB. This is not the quickest code.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dynet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b7954f7f1723>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mdynet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mdy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'dynet'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import dynet as dy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b11d4e041c7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Functions to read in the corpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mw2i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mt2i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt2i\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mUNK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mw2i\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<unk>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "# Functions to read in the corpus\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "UNK = w2i[\"<unk>\"]\n",
    "\n",
    "def read_dataset(filename):\n",
    "    \"\"\"\n",
    "    Read data and covert to indices\n",
    "    \"\"\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            tag, sentence = line.lower().strip().split(\" ||| \")\n",
    "            yield ([w2i[x] for x in sentence.split(\" \")], t2i[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_n_hot(X, vocab_size):\n",
    "    \"\"\"\n",
    "    Convert instances to n-hot encoding\n",
    "    :param X:\n",
    "    :param vocab_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    for word_ids, label in X:\n",
    "        n_hot = np.zeros(vocab_size)\n",
    "        for w_idx in word_ids:\n",
    "            n_hot[w_idx] = 1   # Q1: What happens here?\n",
    "        out.append((n_hot, label))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "train = list(read_dataset(\"data/classes/train.txt\"))\n",
    "\n",
    "vocab_size = max(w2i.values()) + 1 # OOV\n",
    "train = convert_to_n_hot(train, vocab_size)\n",
    "w2i = defaultdict(lambda: UNK, w2i) # freeze vocab\n",
    "dev = list(read_dataset(\"data/classes/dev.txt\"))\n",
    "dev = convert_to_n_hot(dev, vocab_size)\n",
    "\n",
    "ntags = len(t2i)\n",
    "print(vocab_size, ntags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the label of the first instance\n",
    "train[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start DyNet and define trainer\n",
    "model = dy.Model()\n",
    "trainer = dy.SimpleSGDTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "hidden_size = 100\n",
    "W1 = model.add_parameters((hidden_size, vocab_size))\n",
    "b1 = model.add_parameters(hidden_size)\n",
    "\n",
    "W_sm = model.add_parameters((ntags, hidden_size))    # Softmax weights\n",
    "b_sm = model.add_parameters((ntags))                # Softmax bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to calculate scores for one value\n",
    "def calc_scores(input_vec):\n",
    "    dy.renew_cg()\n",
    "    n_hot = dy.inputVector(input_vec)\n",
    "    h = dy.tanh(dy.parameter(W1) * n_hot + dy.parameter(b1))\n",
    "    score = dy.parameter(W_sm) * h + dy.parameter(b_sm)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ITER in range(20):\n",
    "    # Perform training\n",
    "    random.shuffle(train)\n",
    "    train_loss = 0.0\n",
    "    start = time.time()\n",
    "    for words, tag in train:\n",
    "        my_loss = dy.pickneglogsoftmax(calc_scores(words), tag)\n",
    "        train_loss += my_loss.value()\n",
    "        my_loss.backward()\n",
    "        trainer.update()\n",
    "    print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss/len(train), time.time()-start))\n",
    "    # Perform testing\n",
    "    test_correct = 0.0\n",
    "    for words, tag in dev:\n",
    "        predict = dy.softmax(calc_scores(words)).npvalue().argmax()\n",
    "        if predict == tag:\n",
    "            test_correct += 1\n",
    "    print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
