{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DLNLP W4 Notebook 2\n",
    "## Two-layer neural network for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate a simple data set for binary classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "t_train = []\n",
    "\n",
    "for mu, c in [([1.,1.], 1), ([-1., -1.], 1), ([1., -1.], 0), ([-1., 1.], 2)]:\n",
    "    X_train.append(np.random.multivariate_normal(np.array(mu), .2*np.eye(2), 50))\n",
    "    t_train.append(np.ones(50)*c)\n",
    "    \n",
    "X_train = np.concatenate(X_train)\n",
    "t_train = np.concatenate(t_train)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train[t_train==0, 0], X_train[t_train==0, 1], label=\"Class 0\")\n",
    "ax.scatter(X_train[t_train==1, 0], X_train[t_train==1, 1], label=\"Class 1\")\n",
    "ax.scatter(X_train[t_train==2, 0], X_train[t_train==2, 1], label=\"Class 2\")\n",
    "ax.set_xlabel(r'$X_train_1$')\n",
    "ax.set_ylabel(r'$X_train_2$')\n",
    "ax.legend()\n",
    "\n",
    "# Conver t_train to 1-of-K\n",
    "t_train = np.eye(3)[t_train.astype(int)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we define the graph for a two-layer neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output\n",
    "x = tf.placeholder(tf.float32, [None, 2])\n",
    "t = tf.placeholder(tf.float32, [None, 3])\n",
    "\n",
    "# Defined the model parameters\n",
    "W1 = tf.get_variable(\"W1\", [2, 5], initializer=tf.random_normal_initializer)\n",
    "b1 = tf.get_variable(\"b1\", [5], initializer=tf.random_normal_initializer)\n",
    "W2 = tf.get_variable(\"W2\", [5, 3], initializer=tf.random_normal_initializer)\n",
    "b2 = tf.get_variable(\"b2\", [3], initializer=tf.random_normal_initializer)\n",
    "    \n",
    "# Construct model\n",
    "a1 = tf.matmul(x, W1) + b1\n",
    "z1 = tf.nn.tanh(a1)\n",
    "a2 = tf.matmul(z1, W2) + b2\n",
    "y = tf.nn.softmax(a2)\n",
    "\n",
    "# Variables for prediction and accuracy\n",
    "prediction = tf.argmax(y, 1)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(prediction, tf.argmax(t, 1)), tf.float32))\n",
    "\n",
    "# Difine the loss function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=t, logits=a2))\n",
    "\n",
    "# Define the optimizer operation\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "# Make an operation that initializes the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we run a session to train the network and evaluate the accoracy on the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.linspace(0, 1, 100)[:, np.newaxis]\n",
    "y_value_list = []\n",
    "\n",
    "# Start a new session\n",
    "with tf.Session() as session:\n",
    "    # Initialize the values\n",
    "    session.run(init)\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(10000):\n",
    "        _, loss_value = session.run([optimizer, loss], feed_dict={x: X_train, t: t_train, learning_rate: 0.01})\n",
    "        \n",
    "        if epoch % 1000 == 0:\n",
    "            print(\"Epoch: \", epoch, \"loss =\", loss_value)            \n",
    "            \n",
    "    print(\"Optimization done\")\n",
    "\n",
    "    # Evaluate the accuracy on the test set\n",
    "    accuracy_value, y_train = session.run([accuracy, y], feed_dict={x: X_train, t: t_train})\n",
    "    print(\"Accuracy:\", accuracy_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "correct_mask = np.argmax(t_train, axis=1) == np.argmax(y_train, axis=1)\n",
    "incorrect_mask = np.logical_not(correct_mask)\n",
    "\n",
    "ax.scatter(X_train[correct_mask, 0], X_train[correct_mask, 1], color='C0', label=\"Correct\")\n",
    "ax.scatter(X_train[incorrect_mask, 0], X_train[incorrect_mask, 1], color='C3', label=\"Incorrect\")\n",
    "\n",
    "ax.set_xlabel(r'$X_train_1$')\n",
    "ax.set_ylabel(r'$X_train_2$')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
