{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment classification with logistic regression (in Sklearn)\n",
    "\n",
    "The goal of this first exercise is to make you acquainted with the data, understand how instances are represented, and implement a traditional baseline in `sklearn`.\n",
    "\n",
    "To install the package:\n",
    "\n",
    "```\n",
    "pip install scikit-learn\n",
    "```\n",
    "\n",
    "### References:\n",
    "\n",
    "* [sklearn tutorial](https://github.com/bplank/2018-ma-notebooks/blob/master/01_Intro_to_ML.ipynb)\n",
    "* [Machine Learning 101 with sklearn](https://github.com/bplank/2018-ma-notebooks/blob/master/01_Intro_to_ML.ipynb)\n",
    "\n",
    "\n",
    "### Exercise 1\n",
    "```\n",
    "Q1) Examine the code - How is the text represented? What is the difference between fit_transform and transform? (Hint: check the sklearn documentation) \n",
    "Q2) How many labels are there per class in the training data? Which class is the least frequent?\n",
    "Q3) Add code to train and evaluate the classifier. What accuracy do you get? Which class is the most difficult to get correct?\n",
    "Q4) The code implements a simple baseline to compare your system to. What is this baseline?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data..\n",
      "vectorize data..\n",
      "vectorize data..\n",
      "{'3': 2322, '4': 1288, '2': 1624, '1': 2218, '0': 1092}\n",
      "#train instances: 8544 #dev: 1101\n",
      "train (fit) model..\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "predict..\n",
      "===== dev set ====\n",
      "Base accuracy:   21.25\n",
      "Classifier:      35.33\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_data(filename, vectorizer, train=False):\n",
    "    \"\"\"\n",
    "    loads the movie review data\n",
    "    \"\"\"\n",
    "    labels, sentences = [],[]\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            tag, sentence = line.lower().strip().split(\" ||| \")\n",
    "            labels.append(tag)\n",
    "            sentences.append(sentence)\n",
    "    print(\"vectorize data..\")\n",
    "    if train:\n",
    "        X = vectorizer.fit_transform(sentences) # Q1: make sure you understand the difference between fit_transform and transform\n",
    "    else:\n",
    "        X = vectorizer.transform(sentences)\n",
    "\n",
    "    y = labels\n",
    "    assert (X.shape[0] == len(y))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "## read input data\n",
    "print(\"load data..\")\n",
    "vectorizer = CountVectorizer() # Q1: What does the CountVectorizer() do?\n",
    "X_train, y_train = load_data(\"data/classes/train.txt\", vectorizer, train=True)\n",
    "X_dev, y_dev = load_data(\"data/classes/dev.txt\", vectorizer)\n",
    "\n",
    "\n",
    "label_occurences = {}\n",
    "for l in y_train:\n",
    "    label_occurences[lab] = label_occurences.get(lab, 0) + 1\n",
    "    \n",
    "print(\"label occurences:\")\n",
    "print(label_occurences)\n",
    "\n",
    "print(\"#train instances: {} #dev: {}\".format(X_train.shape[0], X_dev.shape[0]))\n",
    "\n",
    "### Q3: Train and evaluate the classifier on the dev set -- add your code here\n",
    "# Create linear regression object\n",
    "clf = LogisticRegression()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"train (fit) model..\")\n",
    "print(clf) # shows model and its parameters\n",
    "\n",
    "\n",
    "print(\"predict..\")\n",
    "y_predicted_dev = clf.predict(X_dev)\n",
    "\n",
    "## end add your code \n",
    "\n",
    "## Q3: Add a simple baseline -- what happens here?\n",
    "base = DummyClassifier()\n",
    "base.fit(X_train, y_train)\n",
    "baseline_dev = base.predict(X_dev)\n",
    "\n",
    "### evaluate\n",
    "accuracy_dev = accuracy_score(y_dev, y_predicted_dev)\n",
    "\n",
    "print(\"===== dev set ====\")\n",
    "print(\"Base accuracy:   {0:.2f}\".format(accuracy_score(y_dev, baseline_dev)*100))\n",
    "print(\"Classifier:      {0:.2f}\".format(accuracy_dev*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
